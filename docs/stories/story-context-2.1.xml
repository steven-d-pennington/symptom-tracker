<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>1</storyId>
    <title>Time-window Correlation Engine with Extended Windows</title>
    <status>Ready</status>
    <generatedAt>2025-10-17</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/story-2.1.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>user</asA>
    <iWant>see correlations between foods and symptoms across various time delays</iWant>
    <soThat>I can identify triggers that appear hours or even days after consumption</soThat>
    <tasks>
      - Define window boundaries and binning strategy (ms ranges)
      - Implement chi-square based correlation per window with alternative coefficient approach
      - Build background job (cron + API) and cache results by pair+window
      - Integrate with repositories using indexed queries first; batch data loads
      - Add unit/integration/performance tests and best-window selection
    </tasks>
  </story>

  <acceptanceCriteria>
    1) Analyze windows: 15min, 30min, 1hr, 2–4hrs, 6–12hrs, 24hrs, 48hrs, 72hrs
    2) For each food–symptom pair, identify strongest window
    3) Use statistical methods (chi-square preferred; correlation coefficient as needed)
    4) Non-blocking background job performs analysis; UI remains responsive
  </acceptanceCriteria>

  <artifacts>
    <docs>
      - docs/PRD.md (FR006/FR007 correlation requirements)
      - docs/solution-architecture.md (correlation engine, background jobs, caching)
      - docs/tech-spec-epic-E2.md (Epic 2 technical specification)
      - docs/epic-stories.md (Story 2.1 ACs and scope)
    </docs>
    <code>
      - src/lib/repositories/medicationEventRepository.ts ([userId+timestamp] index pattern)
      - src/lib/repositories/triggerEventRepository.ts ([userId+timestamp] index pattern)
      - src/lib/repositories/foodEventRepository.ts (events source; add [userId+timestamp] for efficient range scans)
      - src/lib/db/schema.ts (event models; AnalysisResultRecord/analysisResults table for caching)
      - src/lib/services/correlation/CorrelationService.ts (NEW)
      - api routes: /api/correlation/* (cron trigger + fetch endpoints)
    </code>
    <dependencies>
      - Dexie/IndexedDB (local-first event storage)
      - Background jobs (Vercel Cron)
      - TypeScript/Jest for logic and tests
    </dependencies>
  </artifacts>

  <constraints>
    - Performance: always use indexed range scans ([userId+timestamp]) then bin; avoid full scans
    - Local-first: scope datasets (e.g., last N days) when running locally; offload heavy compute to server cron
    - Caching: 24h TTL for results; invalidate on new events; prefer last-known results when recomputing
    - Confidence: initial heuristic (sample size + effect size); formal model deferred to Story 2.4
    - Error handling: strict TypeScript, try/catch around IO; avoid blocking UI paths
  </constraints>

  <interfaces>
    - CorrelationService
      - computePair(userId: string, foodId: string, symptomId: string, range: {start:number; end:number}): WindowScores[]
      - bestWindow(scores: WindowScores[]): { window: string; score: number; sampleSize: number }
      - scheduleRecompute(userId: string, dateRange?: {start:number; end:number}): Promise<void>
    - Repositories (read-only for analysis)
      - foodEventRepository.findByDateRange(userId, start, end)
      - symptomInstanceRepository.findByDateRange(userId, start, end) (add if not present)
    - Cache (analysisResults)
      - get(userId, key)
      - set(userId, key, data, ttlMs)
  </interfaces>

  <tests>
    <standards>Use Jest for unit/integration tests. Favor deterministic synthetic datasets to validate known correlations. Maintain ≥80% coverage for correlation service.</standards>
    <locations>
      - src/lib/services/correlation/__tests__/**
      - src/lib/repositories/__tests__/** (mocks)
    </locations>
    <ideas>
      - Binning correctness for each window range
      - Chi-square score trends with increasing signal; select best window
      - Background job invokes compute over changed date ranges; cache set/get behavior
      - Performance: ensure compute under threshold for typical datasets
    </ideas>
  </tests>
</story-context>

